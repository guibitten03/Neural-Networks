{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    def __init__(self, w_size, bias):\n",
    "        \n",
    "        self.weights = np.random.random(w_size + 1)\n",
    "        self.weights[0] = bias\n",
    "        \n",
    "        \n",
    "    def _calculate(self, input):\n",
    "        output = input * self.weights[1:]\n",
    "        output = output - self.weights[0]\n",
    "        output = output.sum()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bipolar_step(input):\n",
    "    output = 1 if input >= 0 else -1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline():\n",
    "    def __init__(self, l_rate):\n",
    "        self.dot = Neuron(4, -1)\n",
    "        self.l_rate = l_rate\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.input = np.array(input)\n",
    "        self.output = self.dot._calculate(self.input[1:])\n",
    "        \n",
    "        self.grad()\n",
    "            \n",
    "            \n",
    "    def grad(self):\n",
    "        \n",
    "        self.x = np.concatenate((np.array([-1]), self.input[1:]))\n",
    "        self.gradient = self.l_rate * ((self.input[0] - self.output) * self.x)\n",
    "        self.dot.weights = self.dot.weights + self.gradient\n",
    "        \n",
    "        \n",
    "    def predict(self, data):\n",
    "        output = self.dot._calculate(data)\n",
    "        \n",
    "        output = bipolar_step(output)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"0.4329;-1.3719;0.7022;-0.8535;1.0000\",\n",
    "    \"0.3024;0.2286;0.8630;2.7909;-1.0000\",\n",
    "    \"0.1349;-0.6445;1.0530;0.5687;-1.0000\",\n",
    "    \"0.3374;-1.7163;0.3670;-0.6283;-1.0000\",\n",
    "    \"1.1434;-0.0485;0.6637;1.2606;1.0000\",\n",
    "    \"1.3749;-0.5071;0.4464;1.3009;1.0000\",\n",
    "    \"0.7221;-0.7587;0.7681;-0.5592;1.0000\",\n",
    "    \"0.4403;-0.8072;0.5154;-0.3129;1.0000\",\n",
    "    \"-0.5231;0.3548;0.2538;1.5776;-1.0000\",\n",
    "    \"0.3255;-2.0000;0.7112;-1.1209;1.0000\",\n",
    "    \"0.5824;1.3915;-0.2291;4.1735;-1.0000\",\n",
    "    \"0.1340;0.6081;0.4450;3.2230;-1.0000\",\n",
    "    \"0.1480;-0.2988;0.4778;0.8649;1.0000\",\n",
    "    \"0.7359;0.1869;-0.0872;2.3584;1.0000\",\n",
    "    \"0.7115;-1.1469;0.3394;0.9573;-1.0000\",\n",
    "    \"0.8251;-1.2840;0.8452;1.2382;-1.0000\",\n",
    "    \"0.1579;0.3712;0.8825;1.7633;1.0000\",\n",
    "    \"0.0033;0.6835;0.5389;2.8249;-1.0000\",\n",
    "    \"0.4243;0.8313;0.2634;3.5855;-1.0000\",\n",
    "    \"1.0490;0.1326;0.9138;1.9792;1.0000\",\n",
    "    \"1.4276;0.5331;-0.0145;3.7286;1.0000\",\n",
    "    \"0.5971;1.4865;0.2904;4.6069;-1.0000\",\n",
    "    \"0.8475;2.1479;0.3179;5.8235;-1.0000\",\n",
    "    \"1.3967;-0.4171;0.6443;1.3927;1.0000\",\n",
    "    \"0.0044;1.5378;0.6099;4.7755;-1.0000\",\n",
    "    \"0.2201;-0.5668;0.0515;0.7829;1.0000\",\n",
    "    \"0.6300;-1.2480;0.8591;0.8093;-1.0000\",\n",
    "    \"-0.2479;0.8960;0.0547;1.7381;1.0000\",\n",
    "    \"-0.3088;-0.0929;0.8659;1.5483;-1.0000\",\n",
    "    \"-0.5180;1.4974;0.5453;2.3993;1.0000\",\n",
    "    \"0.6833;0.8266;0.0829;2.8864;1.0000\",\n",
    "    \"0.4353;-1.4066;0.4207;-0.4879;1.0000\",\n",
    "    \"-0.1069;-3.2329;0.1856;-2.4572;-1.0000\",\n",
    "    \"0.4662;0.6261;0.7304;3.4370;-1.0000\",\n",
    "    \"0.8298;-1.4089;0.3119;1.3235;-1.0000\"\n",
    "\n",
    "]\n",
    "\n",
    "data = [x.split(\";\") for x in data]\n",
    "data = [[float(x) for x in row] for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(data[:25])\n",
    "test = np.array(data[25:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Adaline(l_rate=0.02)\n",
    "\n",
    "for row in train:\n",
    "    model.forward(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 0.0\n",
    "\n",
    "for row in test:\n",
    "    out = model.predict(row[:(len(row) - 1)])\n",
    "    accuracy += 1 if out == row[(len(row) - 1)] else 0\n",
    "    \n",
    "accuracy /= len(test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
